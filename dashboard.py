"""Streamlit ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - ãƒã‚ºãƒã‚¹ãƒˆåˆ†æ"""

import os
import re
from collections import defaultdict

import pandas as pd
import streamlit as st

# ===== ãƒšãƒ¼ã‚¸è¨­å®š =====
st.set_page_config(
    page_title="ãƒã‚ºãƒã‚¹ãƒˆåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ“Š",
    layout="wide",
)


# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° =====
def classify_category(text):
    """ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
    if re.search(r'é”æˆ|åç›Š|ç¨¼ã’ãŸ|ç¨¼ã„ã |æˆåŠŸ|å®Ÿç¸¾|å„²ã‹ã£ãŸ|ã€œä¸‡å††|æœˆå|å¹´å|å£²ä¸Š|å ±é…¬|åˆ©ç›Š', text, re.IGNORECASE):
        return "å®Ÿç¸¾å ±å‘Šç³»"
    if re.search(r'æ–¹æ³•|ã‚„ã‚Šæ–¹|ã‚³ãƒ„|æ‰‹é †|ã‚¹ãƒ†ãƒƒãƒ—|ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯|æ”»ç•¥', text, re.IGNORECASE):
        return "ãƒã‚¦ãƒã‚¦ç³»"
    if re.search(r'ç§ãŒ|åƒ•ãŒ|è‡ªåˆ†ãŒ|å®Ÿéš›ã«|ã‚„ã£ã¦ã¿ãŸ|è©¦ã—ã¦ã¿ãŸ|ä½“é¨“|çµŒé¨“', text, re.IGNORECASE):
        return "ä½“é¨“è«‡ç³»"
    if re.search(r'ã¯ï¼Ÿ|å•é¡Œ|å±é™º|æ³¨æ„|è­¦å‘Š|ã€æ‚²å ±ã€‘|ã€œã™ãã‚‹|ãƒ¤ãƒã„', text, re.IGNORECASE):
        return "å•é¡Œæèµ·ç³»"
    if re.search(r'ãƒ„ãƒ¼ãƒ«|ã‚¢ãƒ—ãƒª|ã‚µãƒ¼ãƒ“ã‚¹|ãŠã™ã™ã‚|ç´¹ä»‹|AI|Claude|ChatGPT|GPT', text, re.IGNORECASE):
        return "ãƒ„ãƒ¼ãƒ«ç´¹ä»‹ç³»"
    if re.search(r'ç™ºè¡¨|ãƒªãƒªãƒ¼ã‚¹|é–‹å§‹|é€Ÿå ±|æœ€æ–°|ãƒ‹ãƒ¥ãƒ¼ã‚¹|å…¬é–‹', text, re.IGNORECASE):
        return "ãƒ‹ãƒ¥ãƒ¼ã‚¹ç³»"
    return "ãã®ä»–"


def find_data_files():
    """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    files = []
    for search_dir in [".", "output"]:
        if not os.path.isdir(search_dir):
            continue
        for f in os.listdir(search_dir):
            if re.match(r"buzz_posts_\d{8}\.(csv|xlsx)$", f):
                files.append(os.path.join(search_dir, f))
    return sorted(files)


def load_data(file_path):
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    if file_path.endswith(".csv"):
        return pd.read_csv(file_path)
    else:
        return pd.read_excel(file_path)


# ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼ =====
st.sidebar.title("ğŸ“Š ãƒã‚ºãƒã‚¹ãƒˆåˆ†æ")
st.sidebar.markdown("---")

# ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
data_files = find_data_files()
if not data_files:
    st.error("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã« buzz_analyzer.py ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

selected_file = st.sidebar.selectbox("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«", data_files)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = load_data(selected_file)

# ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’è¿½åŠ 
df["ã‚«ãƒ†ã‚´ãƒª"] = df["æœ¬æ–‡"].apply(lambda x: classify_category(str(x)))

# ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
st.sidebar.markdown("### ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")

min_likes = st.sidebar.slider(
    "æœ€å°ã„ã„ã­æ•°",
    min_value=0,
    max_value=int(df["ã„ã„ã­æ•°"].max()) if "ã„ã„ã­æ•°" in df.columns else 1000,
    value=0,
    step=50,
)

categories = st.sidebar.multiselect(
    "ã‚«ãƒ†ã‚´ãƒª",
    options=sorted(df["ã‚«ãƒ†ã‚´ãƒª"].unique()),
    default=sorted(df["ã‚«ãƒ†ã‚´ãƒª"].unique()),
)

keyword_filter = st.sidebar.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢")

# ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
df_filtered = df[df["ã„ã„ã­æ•°"] >= min_likes]
df_filtered = df_filtered[df_filtered["ã‚«ãƒ†ã‚´ãƒª"].isin(categories)]
if keyword_filter:
    df_filtered = df_filtered[df_filtered["æœ¬æ–‡"].str.contains(keyword_filter, na=False)]

st.sidebar.markdown(f"**è¡¨ç¤ºä»¶æ•°:** {len(df_filtered)} / {len(df)}ä»¶")


# ===== ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ =====
st.title("ğŸ“Š ãƒã‚ºãƒã‚¹ãƒˆåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ã‚¿ãƒ–
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ æ¦‚è¦", "ğŸ“‹ æŠ•ç¨¿ä¸€è¦§", "ğŸ” è©³ç´°åˆ†æ", "âœï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ"])


# ===== ã‚¿ãƒ–1: æ¦‚è¦ =====
with tab1:
    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æŠ•ç¨¿æ•°", f"{len(df_filtered)}ä»¶")
    with col2:
        st.metric("å¹³å‡ã„ã„ã­", f"{df_filtered['ã„ã„ã­æ•°'].mean():.0f}")
    with col3:
        st.metric("æœ€å¤§ã„ã„ã­", f"{df_filtered['ã„ã„ã­æ•°'].max():,}")
    with col4:
        st.metric("ä¸­å¤®å€¤", f"{df_filtered['ã„ã„ã­æ•°'].median():.0f}")

    st.markdown("---")

    # ãƒãƒ£ãƒ¼ãƒˆ
    col_left, col_right = st.columns(2)

    with col_left:
        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥ å¹³å‡ã„ã„ã­æ•°")
        cat_stats = df_filtered.groupby("ã‚«ãƒ†ã‚´ãƒª")["ã„ã„ã­æ•°"].agg(["mean", "count"]).reset_index()
        cat_stats.columns = ["ã‚«ãƒ†ã‚´ãƒª", "å¹³å‡ã„ã„ã­æ•°", "ä»¶æ•°"]
        cat_stats = cat_stats.sort_values("å¹³å‡ã„ã„ã­æ•°", ascending=True)
        st.bar_chart(cat_stats.set_index("ã‚«ãƒ†ã‚´ãƒª")["å¹³å‡ã„ã„ã­æ•°"])

    with col_right:
        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥ æŠ•ç¨¿æ•°")
        cat_counts = df_filtered["ã‚«ãƒ†ã‚´ãƒª"].value_counts()
        st.bar_chart(cat_counts)

    # ã„ã„ã­æ•°åˆ†å¸ƒ
    st.subheader("ã„ã„ã­æ•°ã®åˆ†å¸ƒ")
    hist_data = df_filtered["ã„ã„ã­æ•°"].clip(upper=df_filtered["ã„ã„ã­æ•°"].quantile(0.95))
    st.bar_chart(hist_data.value_counts().sort_index())


# ===== ã‚¿ãƒ–2: æŠ•ç¨¿ä¸€è¦§ =====
with tab2:
    st.subheader("æŠ•ç¨¿ä¸€è¦§")

    sort_col = st.selectbox("ä¸¦ã³æ›¿ãˆ", ["ã„ã„ã­æ•°", "ãƒªãƒã‚¹ãƒˆæ•°", "ãƒªãƒ—ãƒ©ã‚¤æ•°"], index=0)
    df_sorted = df_filtered.sort_values(sort_col, ascending=False)

    for i, (_, row) in enumerate(df_sorted.head(50).iterrows(), 1):
        with st.expander(
            f"#{i} | â¤ï¸ {row['ã„ã„ã­æ•°']:,} | ğŸ”„ {row['ãƒªãƒã‚¹ãƒˆæ•°']:,} | "
            f"[{row['ã‚«ãƒ†ã‚´ãƒª']}] @{row['ãƒ¦ãƒ¼ã‚¶ãƒ¼å']}"
        ):
            st.markdown(f"**æœ¬æ–‡:**")
            st.text(str(row["æœ¬æ–‡"])[:500])
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ã„ã„ã­", f"{row['ã„ã„ã­æ•°']:,}")
            with col2:
                st.metric("ãƒªãƒã‚¹ãƒˆ", f"{row['ãƒªãƒã‚¹ãƒˆæ•°']:,}")
            with col3:
                st.metric("ãƒªãƒ—ãƒ©ã‚¤", f"{row['ãƒªãƒ—ãƒ©ã‚¤æ•°']:,}")
            if pd.notna(row.get("ãƒã‚¹ãƒˆURL")):
                st.markdown(f"[ãƒã‚¹ãƒˆã‚’è¦‹ã‚‹]({row['ãƒã‚¹ãƒˆURL']})")


# ===== ã‚¿ãƒ–3: è©³ç´°åˆ†æ =====
with tab3:
    st.subheader("è©³ç´°åˆ†æ")

    analysis_type = st.selectbox(
        "åˆ†æã‚¿ã‚¤ãƒ—",
        ["CTAåˆ†æ", "æ„Ÿæƒ…åˆ†æ", "æ–‡å­—æ•°åˆ†æ", "TOPæŠ•ç¨¿ã®å…±é€šç‚¹"],
    )

    if analysis_type == "CTAåˆ†æ":
        cta_patterns = {
            "ã„ã„ã­ç³»": r'ã„ã„ã­|ğŸ‘|ãƒãƒ¼ãƒˆ',
            "ä¿å­˜ç³»": r'ä¿å­˜|ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯',
            "ãƒ•ã‚©ãƒ­ãƒ¼ç³»": r'ãƒ•ã‚©ãƒ­ãƒ¼|follow',
            "ã‚·ã‚§ã‚¢ç³»": r'ãƒªãƒã‚¹ãƒˆ|RT|ã‚·ã‚§ã‚¢|æ‹¡æ•£',
            "ã‚³ãƒ¡ãƒ³ãƒˆç³»": r'ã‚³ãƒ¡ãƒ³ãƒˆ|è¿”ä¿¡|æ•™ãˆã¦',
        }

        cta_results = []
        for cta_type, pattern in cta_patterns.items():
            matches = df_filtered[df_filtered["æœ¬æ–‡"].str.contains(pattern, na=False, flags=re.IGNORECASE)]
            cta_results.append({
                "CTAç¨®é¡": cta_type,
                "ä»¶æ•°": len(matches),
                "å¹³å‡ã„ã„ã­": matches["ã„ã„ã­æ•°"].mean() if len(matches) > 0 else 0,
            })

        no_cta = df_filtered.copy()
        for pattern in cta_patterns.values():
            no_cta = no_cta[~no_cta["æœ¬æ–‡"].str.contains(pattern, na=False, flags=re.IGNORECASE)]
        cta_results.append({
            "CTAç¨®é¡": "CTAãªã—",
            "ä»¶æ•°": len(no_cta),
            "å¹³å‡ã„ã„ã­": no_cta["ã„ã„ã­æ•°"].mean() if len(no_cta) > 0 else 0,
        })

        cta_df = pd.DataFrame(cta_results)
        st.dataframe(cta_df, use_container_width=True)
        st.bar_chart(cta_df.set_index("CTAç¨®é¡")["å¹³å‡ã„ã„ã­"])

    elif analysis_type == "æ„Ÿæƒ…åˆ†æ":
        emotion_patterns = {
            "æœŸå¾…": r'ãƒãƒ£ãƒ³ã‚¹|å¯èƒ½æ€§|ç¨¼ã’ã‚‹|å„²ã‹ã‚‹|æˆåŠŸ|é”æˆ|å®Ÿç¾|ã§ãã‚‹',
            "é©šã": r'ã¾ã•ã‹|ã³ã£ãã‚Š|é©šã|ã™ã”ã„|ã‚„ã°ã„',
            "å…±æ„Ÿ": r'ã‚ã‹ã‚‹|ãã†ãã†|ã‚ã‚‹ã‚ã‚‹|åŒã˜|ç§ã‚‚',
            "ææ€–": r'å±é™º|æ€–ã„|ãƒªã‚¹ã‚¯|å¤±æ•—|æ|ãƒ¤ãƒã„|æœ€æ‚ª',
        }

        emotion_results = []
        for emotion, pattern in emotion_patterns.items():
            matches = df_filtered[df_filtered["æœ¬æ–‡"].str.contains(pattern, na=False, flags=re.IGNORECASE)]
            emotion_results.append({
                "æ„Ÿæƒ…": emotion,
                "ä»¶æ•°": len(matches),
                "å¹³å‡ã„ã„ã­": matches["ã„ã„ã­æ•°"].mean() if len(matches) > 0 else 0,
            })

        em_df = pd.DataFrame(emotion_results)
        st.dataframe(em_df, use_container_width=True)
        st.bar_chart(em_df.set_index("æ„Ÿæƒ…")["å¹³å‡ã„ã„ã­"])

    elif analysis_type == "æ–‡å­—æ•°åˆ†æ":
        df_temp = df_filtered.copy()
        df_temp["æ–‡å­—æ•°"] = df_temp["æœ¬æ–‡"].apply(lambda x: len(str(x)))

        col1, col2 = st.columns(2)
        with col1:
            st.metric("å¹³å‡æ–‡å­—æ•°", f"{df_temp['æ–‡å­—æ•°'].mean():.0f}å­—")
        with col2:
            st.metric("ä¸­å¤®å€¤", f"{df_temp['æ–‡å­—æ•°'].median():.0f}å­—")

        # ä¸Šä½25%ã¨ä¸‹ä½25%ã®æ¯”è¼ƒ
        top_25 = df_temp.nlargest(len(df_temp) // 4, "ã„ã„ã­æ•°")
        bottom_25 = df_temp.nsmallest(len(df_temp) // 4, "ã„ã„ã­æ•°")

        st.markdown("### ã„ã„ã­æ•°ä¸Šä½25% vs ä¸‹ä½25%")
        comp_col1, comp_col2 = st.columns(2)
        with comp_col1:
            st.metric("ä¸Šä½25%ã®å¹³å‡æ–‡å­—æ•°", f"{top_25['æ–‡å­—æ•°'].mean():.0f}å­—")
        with comp_col2:
            st.metric("ä¸‹ä½25%ã®å¹³å‡æ–‡å­—æ•°", f"{bottom_25['æ–‡å­—æ•°'].mean():.0f}å­—")

    elif analysis_type == "TOPæŠ•ç¨¿ã®å…±é€šç‚¹":
        top10 = df_filtered.nlargest(10, "ã„ã„ã­æ•°")

        st.markdown("### TOP10æŠ•ç¨¿")
        for i, (_, row) in enumerate(top10.iterrows(), 1):
            st.markdown(f"**{i}ä½** ({row['ã„ã„ã­æ•°']:,}ã„ã„ã­) - [{row['ã‚«ãƒ†ã‚´ãƒª']}]")
            st.text(str(row["æœ¬æ–‡"])[:200])
            st.markdown("---")

        # å…±é€šç‚¹åˆ†æ
        st.markdown("### å…±é€šç‚¹")
        avg_len = top10["æœ¬æ–‡"].apply(lambda x: len(str(x))).mean()
        top_cats = top10["ã‚«ãƒ†ã‚´ãƒª"].value_counts()

        st.markdown(f"- **å¹³å‡æ–‡å­—æ•°:** {avg_len:.0f}å­—")
        st.markdown(f"- **æœ€å¤šã‚«ãƒ†ã‚´ãƒª:** {top_cats.index[0]}ï¼ˆ{top_cats.values[0]}ä»¶ï¼‰")

        has_url = top10["æœ¬æ–‡"].str.contains(r'https?://', na=False).sum()
        st.markdown(f"- **URLå«ã‚€:** {has_url}ä»¶ / 10ä»¶")

        has_emoji = top10["æœ¬æ–‡"].str.contains(r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿ğŸš€-ğŸ›¿ğŸ¤€-ğŸ§¿ğŸ©°-ğŸ«¿]', na=False, regex=True).sum()
        st.markdown(f"- **çµµæ–‡å­—ã‚ã‚Š:** {has_emoji}ä»¶ / 10ä»¶")


# ===== ã‚¿ãƒ–4: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ =====
with tab4:
    st.subheader("âœï¸ ãƒã‚ºãƒã‚¹ãƒˆ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ")
    st.markdown("åˆ†æãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€ãƒã‚ºã‚Šã‚„ã™ã„æŠ•ç¨¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    if st.button("ğŸ² ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹", type="primary"):
        try:
            from generate_posts import generate_posts, extract_trending_topics, extract_effective_ctas

            posts, tools, works, ctas = generate_posts(df_filtered, n=5)

            st.markdown("### ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±")
            st.markdown(f"- **äººæ°—ãƒ„ãƒ¼ãƒ«:** {', '.join(tools)}")
            st.markdown(f"- **äººæ°—ã‚¸ãƒ£ãƒ³ãƒ«:** {', '.join(works)}")
            st.markdown(f"- **åŠ¹æœçš„ãªCTA:** {', '.join(ctas[:3])}")

            st.markdown("---")

            for i, post in enumerate(posts, 1):
                st.markdown(f"### ç”Ÿæˆæ¡ˆ{i}: {post['type']}")
                st.code(post["text"] + (f"\n\n{post['cta']}" if post.get("cta") else ""), language=None)
                st.info(f"ğŸ’¡ **Tips:** {post['tips']}")

        except Exception as e:
            st.error(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    st.markdown("---")
    st.markdown("### ä½¿ã„æ–¹")
    st.markdown("""
    1. ã€Œãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™
    2. æ°—ã«å…¥ã£ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é¸ã¶
    3. æ•°å­—ãƒ»ãƒ„ãƒ¼ãƒ«åã‚’è‡ªåˆ†ã®å®Ÿç¸¾ã«ç½®ãæ›ãˆ
    4. çµµæ–‡å­—ã‚’2ã€œ3å€‹è¿½åŠ 
    5. æœ7ã€œ9æ™‚ or å¤œ19ã€œ21æ™‚ã«æŠ•ç¨¿
    """)
