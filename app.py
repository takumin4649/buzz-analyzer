"""ãƒã‚ºæŠ•ç¨¿ è“„ç©åˆ†æ Streamlit ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""

import os
import sqlite3
import tempfile
from collections import Counter
from datetime import datetime

import pandas as pd
import plotly.express as px
import streamlit as st

from algorithm_analysis import (
    analyze_discussion_algorithm_value,
    analyze_dwell_potential,
    analyze_early_engagement_potential,
    analyze_link_impact,
    analyze_thread_potential,
    analyze_tone,
    analyze_tone_distribution,
    calculate_algorithm_score,
    predict_early_engagement,
)
from analyze_posts import calculate_buzz_score
from buzz_score_v2 import calculate_buzz_score_v2
from import_csv import DB_PATH, import_file, init_db
from reader_psychology import analyze_reader_psychology

st.set_page_config(page_title="ãƒã‚ºåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", layout="wide")
st.title("ãƒã‚ºæŠ•ç¨¿ åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

init_db()


def get_conn():
    return sqlite3.connect(DB_PATH)


def get_account_list():
    """posts + account_followers ã®å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ABCé †ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–ï¼‰ã§è¿”ã™"""
    conn = get_conn()
    rows = conn.execute(
        """
        SELECT DISTINCT account FROM posts WHERE account != ''
        UNION
        SELECT account FROM account_followers WHERE account != ''
        """
    ).fetchall()
    conn.close()
    return sorted([r[0] for r in rows], key=str.lower)


def account_filter_ui(label="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰",
                      placeholder="ä¾‹: Mr_boten",
                      key_prefix="acct"):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ + ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã®UIéƒ¨å“ã€‚é¸æŠã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’è¿”ã™"""
    account_list = get_account_list()
    filter_val = st.text_input(label, placeholder=placeholder, key=f"{key_prefix}_filter")
    if filter_val:
        filtered = [a for a in account_list if filter_val.lower() in a.lower()]
        if not filtered:
            st.caption("ä¸€è‡´ã™ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…¨ä»¶è¡¨ç¤ºä¸­ã€‚")
            filtered = account_list
    else:
        filtered = account_list
    selected = st.selectbox("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’é¸æŠ", filtered, key=f"{key_prefix}_select")
    return selected


def to_naive_datetime(series):
    """ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ä»˜ããƒ»ãªã—æ··åœ¨ã‚’tz-naiveã«çµ±ä¸€ã™ã‚‹"""
    result = pd.to_datetime(series, errors="coerce", utc=True)
    if hasattr(result, "dt"):
        return result.dt.tz_convert(None)
    return result


# ============================================================
# CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ============================================================
st.header("ãƒ‡ãƒ¼ã‚¿è¿½åŠ ")
uploaded = st.file_uploader(
    "CSV / Excel ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯ï¼‰",
    type=["csv", "xlsx", "xls"]
)

if uploaded:
    ext = os.path.splitext(uploaded.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
        tmp.write(uploaded.read())
        tmp_path = tmp.name
    with st.spinner("ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­..."):
        try:
            inserted, skipped_rows = import_file(tmp_path)
            skipped = len(skipped_rows)
            if inserted > 0:
                st.success(f"æ–°è¦ç™»éŒ²: {inserted}ä»¶ / ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {skipped}ä»¶")
            else:
                st.info(f"æ–°è¦ç™»éŒ²: 0ä»¶ï¼ˆå…¨{skipped}ä»¶ã¯æ—¢ã«DBæ¸ˆã¿ï¼‰")

            if skipped > 0:
                with st.expander(f"ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸé‡è¤‡æŠ•ç¨¿ã‚’ç¢ºèªï¼ˆ{skipped}ä»¶ï¼‰"):
                    df_skip = pd.DataFrame(skipped_rows)[["account", "text", "likes", "date"]]
                    df_skip["text"] = df_skip["text"].str[:60]
                    df_skip = df_skip.rename(columns={
                        "account": "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "text": "æœ¬æ–‡ï¼ˆå…ˆé ­60å­—ï¼‰",
                        "likes": "ã„ã„ã­", "date": "æŠ•ç¨¿æ—¥æ™‚"
                    })
                    st.dataframe(df_skip, use_container_width=True, hide_index=True)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    os.unlink(tmp_path)
    st.rerun()

st.divider()

# ============================================================
# ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¦‚è¦
# ============================================================
st.header("ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")

conn = get_conn()
total = conn.execute("SELECT COUNT(*) FROM posts").fetchone()[0]
latest_v2 = conn.execute(
    "SELECT correlation, sample_size, date FROM score_history WHERE version='v2' ORDER BY date DESC LIMIT 1"
).fetchone()
latest_v1 = conn.execute(
    "SELECT correlation FROM score_history WHERE version='v1' ORDER BY date DESC LIMIT 1"
).fetchone()
sources = conn.execute("SELECT COUNT(DISTINCT source_file) FROM posts").fetchone()[0]
conn.close()

col1, col2, col3, col4, col5 = st.columns(5)
col1.metric("ç·æŠ•ç¨¿æ•°", f"{total}ä»¶")
col2.metric("ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æ•°", f"{sources}ä»¶")
if latest_v2:
    col3.metric("v2ç›¸é–¢ä¿‚æ•°", f"{latest_v2[0]:+.3f}")
    col4.metric("v1ç›¸é–¢ä¿‚æ•°", f"{latest_v1[0]:+.3f}" if latest_v1 else "æœªè¨ˆç®—")
    col5.metric("æœ€çµ‚è¨ˆç®—", latest_v2[2][:10] if latest_v2[2] else "---")
else:
    col3.metric("v2ç›¸é–¢ä¿‚æ•°", "æœªè¨ˆç®—")
    col4.metric("v1ç›¸é–¢ä¿‚æ•°", "æœªè¨ˆç®—")
    col5.metric("æœ€çµ‚è¨ˆç®—", "---")
    st.info("ã‚¹ã‚³ã‚¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `python recalculate_score.py` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

st.divider()

# ============================================================
# ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ
# ============================================================
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10 = st.tabs([
    "æŠ•ç¨¿ä¸€è¦§", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ¥åˆ†æ", "ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥", "æŠ•ç¨¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ",
    "ã‚¹ã‚³ã‚¢è¨ºæ–­", "ã‚¹ã‚³ã‚¢ç²¾åº¦æ¨ç§»", "é‡è¤‡ç®¡ç†", "æŠ•ç¨¿ä½œæˆ",
    "èª­è€…å¿ƒç†åˆ†æ", "Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ†æ",
])

# ============================================================
# TAB1: æŠ•ç¨¿ä¸€è¦§
# ============================================================
with tab1:
    st.header("æŠ•ç¨¿ä¸€è¦§")

    if total > 0:
        conn = get_conn()
        df_posts = pd.read_sql(
            "SELECT id, account, text, likes, retweets, replies, impressions, date, source_file FROM posts",
            conn
        )
        conn.close()

        with st.spinner("ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ä¸­..."):
            df_posts["v2ã‚¹ã‚³ã‚¢"] = df_posts.apply(
                lambda r: calculate_buzz_score_v2(str(r["text"] or ""), str(r["date"] or ""))["total_score"],
                axis=1
            )

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        col_f1, col_f2, col_f3 = st.columns(3)
        with col_f1:
            account_filter = st.text_input("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã§çµã‚Šè¾¼ã¿ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", "")
        with col_f2:
            keyword_filter = st.text_input("ãƒ†ã‚­ã‚¹ãƒˆå†…ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢", "")
        with col_f3:
            source_options = ["ã™ã¹ã¦"] + sorted(df_posts["source_file"].dropna().unique().tolist())
            source_filter = st.selectbox("ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã§çµã‚Šè¾¼ã¿", source_options)

        df_filtered = df_posts.copy()
        if account_filter:
            df_filtered = df_filtered[df_filtered["account"].str.contains(account_filter, case=False, na=False)]
        if keyword_filter:
            df_filtered = df_filtered[df_filtered["text"].str.contains(keyword_filter, case=False, na=False)]
        if source_filter != "ã™ã¹ã¦":
            df_filtered = df_filtered[df_filtered["source_file"] == source_filter]

        st.caption(f"è¡¨ç¤ºä»¶æ•°: {len(df_filtered)}ä»¶ / å…¨{total}ä»¶")

        sort_options = {
            "v2ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„é †ï¼‰":        ("v2ã‚¹ã‚³ã‚¢", False),
            "ã„ã„ã­æ•°ï¼ˆå¤šã„é †ï¼‰":         ("likes", False),
            "ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ï¼ˆé«˜ã„é †ï¼‰": ("impressions", False),
            "æŠ•ç¨¿æ—¥æ™‚ï¼ˆæ–°ã—ã„é †ï¼‰":       ("date", False),
            "æŠ•ç¨¿æ—¥æ™‚ï¼ˆå¤ã„é †ï¼‰":         ("date", True),
        }
        sort_label = st.selectbox("ä¸¦ã³é †", list(sort_options.keys()))
        sort_col, sort_asc = sort_options[sort_label]

        df_display = df_filtered[[
            "account", "text", "likes", "retweets", "replies", "impressions",
            "v2ã‚¹ã‚³ã‚¢", "date", "source_file"
        ]].copy()
        df_display["text"] = df_display["text"].str[:80]
        df_display = df_display.rename(columns={
            "account":     "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ",
            "text":        "æœ¬æ–‡ï¼ˆå…ˆé ­80å­—ï¼‰",
            "likes":       "ã„ã„ã­",
            "retweets":    "RT",
            "replies":     "ãƒªãƒ—ãƒ©ã‚¤",
            "impressions": "ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³",
            "date":        "æŠ•ç¨¿æ—¥æ™‚",
            "source_file": "ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«",
        })
        df_display = df_display.sort_values(sort_col, ascending=sort_asc)
        st.dataframe(df_display, use_container_width=True, height=500, hide_index=True)
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã§ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

# ============================================================
# TAB2: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ¥åˆ†æ
# ============================================================
with tab2:
    st.header("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ¥åˆ†æ")

    if total > 0:
        conn = get_conn()
        df_acc = pd.read_sql(
            """
            SELECT
                p.account,
                COUNT(*) as æŠ•ç¨¿æ•°,
                ROUND(AVG(p.likes), 1) as å¹³å‡ã„ã„ã­,
                ROUND(AVG(p.retweets), 1) as å¹³å‡RT,
                ROUND(AVG(p.replies), 1) as å¹³å‡ãƒªãƒ—ãƒ©ã‚¤,
                ROUND(AVG(p.impressions), 0) as å¹³å‡ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³,
                MAX(p.likes) as æœ€å¤§ã„ã„ã­,
                COALESCE(af.followers, 0) as ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
            FROM posts p
            LEFT JOIN account_followers af ON p.account = af.account
            WHERE p.account != ''
            GROUP BY p.account
            ORDER BY å¹³å‡ã„ã„ã­ DESC
            """,
            conn
        )
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ï¼ˆãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ç™»éŒ²æ¸ˆã¿ã®ã¿ï¼‰
        mask = df_acc["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"] > 0
        df_acc["ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡(%)"] = None
        df_acc.loc[mask, "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡(%)"] = (
            df_acc.loc[mask, "å¹³å‡ã„ã„ã­"] / df_acc.loc[mask, "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"] * 100
        ).round(2)
        conn.close()

        st.subheader("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ¯”è¼ƒè¡¨")
        st.dataframe(df_acc, use_container_width=True, hide_index=True)

        st.subheader("å¹³å‡ã„ã„ã­ TOP10")
        st.bar_chart(df_acc.head(10).set_index("account")["å¹³å‡ã„ã„ã­"])

        st.subheader("æŠ•ç¨¿æ•° TOP10")
        st.bar_chart(df_acc.sort_values("æŠ•ç¨¿æ•°", ascending=False).head(10).set_index("account")["æŠ•ç¨¿æ•°"])

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ï¼ˆãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ç™»éŒ²æ¸ˆã¿ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã¿ï¼‰
        df_eng = df_acc[df_acc["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"] > 0].copy()
        if not df_eng.empty:
            st.subheader("ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ï¼ˆã„ã„ã­Ã·ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ï¼‰")
            st.bar_chart(df_eng.set_index("account")["ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡(%)"])

        st.divider()

        # ============================================================
        # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ç™»éŒ²
        # ============================================================
        st.subheader("ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ç™»éŒ²")

        conn = get_conn()
        df_followers = pd.read_sql(
            "SELECT account, followers, updated_at FROM account_followers ORDER BY followers DESC",
            conn
        )
        conn.close()

        # å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä¸€è¦§ï¼ˆposts + account_followersã€ABCé †ï¼‰
        account_list = get_account_list()

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ â†’ ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã«åæ˜ 
        fw_filter = st.text_input(
            "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰",
            key="fw_filter",
            placeholder="ä¾‹: Mr_boten"
        )
        if fw_filter:
            filtered_accounts = [a for a in account_list if fw_filter.lower() in a.lower()]
            if not filtered_accounts:
                st.caption("ä¸€è‡´ã™ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…¨ä»¶è¡¨ç¤ºä¸­ã€‚")
                filtered_accounts = account_list
        else:
            filtered_accounts = account_list

        col_fw1, col_fw2, col_fw3 = st.columns([2, 1, 1])
        with col_fw1:
            fw_account = st.selectbox("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’é¸æŠ", filtered_accounts, key="fw_account")
        with col_fw2:
            existing = df_followers[df_followers["account"] == fw_account]["followers"].values
            default_val = int(existing[0]) if len(existing) > 0 else 0
            fw_count = st.number_input("ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", min_value=0, value=default_val, step=100, key="fw_count")
        with col_fw3:
            st.write("")
            st.write("")
            if st.button("ç™»éŒ²", key="fw_register"):
                conn = get_conn()
                now = datetime.now().isoformat()
                conn.execute(
                    "INSERT OR REPLACE INTO account_followers (account, followers, updated_at) VALUES (?,?,?)",
                    (fw_account, fw_count, now)
                )
                conn.execute(
                    "UPDATE posts SET follower_count=? WHERE account=?",
                    (fw_count, fw_account)
                )
                conn.commit()
                conn.close()
                st.success(f"{fw_account}: {fw_count:,}äººã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
                st.rerun()

        # å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ä¸€è¦§ï¼ˆç™»éŒ²æ¸ˆã¿ãƒ»æœªç™»éŒ²ã‚’å…¨ä»¶è¡¨ç¤ºï¼‰
        st.markdown("**å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ä¸€è¦§**")
        df_all_acc = pd.DataFrame({"account": account_list})
        df_all_merged = df_all_acc.merge(
            df_followers[["account", "followers", "updated_at"]],
            on="account", how="left"
        )
        df_all_merged["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"] = df_all_merged["followers"].apply(
            lambda x: f"{int(x):,}äºº" if pd.notna(x) and x > 0 else "æœªç™»éŒ²"
        )
        df_all_merged["æ›´æ–°æ—¥æ™‚"] = df_all_merged["updated_at"].fillna("").str[:10]
        # ç™»éŒ²æ¸ˆã¿ä»¶æ•°ã®ã‚µãƒãƒªãƒ¼
        registered_cnt = df_all_merged["followers"].notna().sum()
        st.caption(f"ç™»éŒ²æ¸ˆã¿: {registered_cnt}ä»¶ / å…¨{len(account_list)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ")
        st.dataframe(
            df_all_merged[["account", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", "æ›´æ–°æ—¥æ™‚"]].rename(
                columns={"account": "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"}
            ),
            use_container_width=True,
            hide_index=True,
        )

        st.divider()

        # ============================================================
        # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¸¯åˆ¥åˆ†æ
        # ============================================================
        st.subheader("ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¸¯åˆ¥åˆ†æ")

        conn = get_conn()
        df_fw_band = pd.read_sql(
            """
            SELECT
                p.account,
                p.likes,
                p.retweets,
                COALESCE(af.followers, 0) as followers
            FROM posts p
            LEFT JOIN account_followers af ON p.account = af.account
            WHERE af.followers IS NOT NULL AND af.followers > 0
            """,
            conn
        )
        conn.close()

        if not df_fw_band.empty:
            bins = [0, 500, 1000, 5000, 999999999]
            labels = ["500ä»¥ä¸‹", "500-1000", "1000-5000", "5000ä»¥ä¸Š"]
            df_fw_band["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¸¯"] = pd.cut(
                df_fw_band["followers"], bins=bins, labels=labels, right=True
            )
            # 1å›ã®agg()ã§å…¨é …ç›®ã‚’é›†è¨ˆï¼ˆäºŒé‡groupbyã«ã‚ˆã‚‹é•·ã•ä¸ä¸€è‡´ã‚’å›é¿ï¼‰
            band_avg = df_fw_band.groupby("ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¸¯", observed=True).agg(
                ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ•°=("account", "nunique"),
                æŠ•ç¨¿æ•°=("likes", "count"),
                ã„ã„ã­åˆè¨ˆ=("likes", "sum"),
                å¹³å‡ã„ã„ã­=("likes", "mean"),
                å¹³å‡RT=("retweets", "mean"),
                å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°=("followers", "mean"),
            ).round(1).reset_index()

            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ = (ã„ã„ã­åˆè¨ˆ / (å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•° Ã— æŠ•ç¨¿æ•°)) Ã— 100
            # ã‚¼ãƒ­é™¤ç®—ãƒ»NaNå¯¾å¿œ
            band_avg["ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡(%)"] = band_avg.apply(
                lambda r: round(r["ã„ã„ã­åˆè¨ˆ"] / (r["å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"] * r["æŠ•ç¨¿æ•°"]) * 100, 2)
                if r["å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"] > 0 and r["æŠ•ç¨¿æ•°"] > 0 else None,
                axis=1,
            )

            st.dataframe(
                band_avg.drop(columns=["ã„ã„ã­åˆè¨ˆ"]),
                use_container_width=True,
                hide_index=True,
            )
        else:
            st.info("ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã‚’ç™»éŒ²ã™ã‚‹ã¨ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¸¯åˆ¥åˆ†æãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ============================================================
# TAB3: ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥
# ============================================================
with tab3:
    st.header("ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥åˆ†æ")

    if total > 0:
        conn = get_conn()
        df_src = pd.read_sql(
            """
            SELECT
                source_file,
                COUNT(*) as æŠ•ç¨¿æ•°,
                ROUND(AVG(likes), 1) as å¹³å‡ã„ã„ã­,
                ROUND(AVG(retweets), 1) as å¹³å‡RT,
                ROUND(AVG(impressions), 0) as å¹³å‡ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³,
                MAX(likes) as æœ€å¤§ã„ã„ã­,
                MIN(date) as æœ€å¤æŠ•ç¨¿æ—¥,
                MAX(date) as æœ€æ–°æŠ•ç¨¿æ—¥,
                COUNT(DISTINCT account) as ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæ•°
            FROM posts
            GROUP BY source_file
            ORDER BY æŠ•ç¨¿æ•° DESC
            """,
            conn
        )
        conn.close()

        st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã‚µãƒãƒªãƒ¼")
        st.dataframe(df_src, use_container_width=True, hide_index=True)

        st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ æŠ•ç¨¿æ•°")
        st.bar_chart(df_src.set_index("source_file")["æŠ•ç¨¿æ•°"])

        st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ å¹³å‡ã„ã„ã­")
        st.bar_chart(df_src.set_index("source_file")["å¹³å‡ã„ã„ã­"])

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã‚“ã§æŠ•ç¨¿ã‚’è¡¨ç¤º
        st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®æŠ•ç¨¿ã‚’ç¢ºèª")
        selected_src = st.selectbox(
            "ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            df_src["source_file"].tolist(),
            key="src_select"
        )
        if selected_src:
            conn = get_conn()
            df_src_posts = pd.read_sql(
                "SELECT account, text, likes, retweets, impressions, date FROM posts WHERE source_file=? ORDER BY likes DESC",
                conn, params=(selected_src,)
            )
            conn.close()
            df_src_posts["text"] = df_src_posts["text"].str[:70]
            df_src_posts = df_src_posts.rename(columns={
                "account": "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "text": "æœ¬æ–‡ï¼ˆå…ˆé ­70å­—ï¼‰",
                "likes": "ã„ã„ã­", "retweets": "RT",
                "impressions": "ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³", "date": "æŠ•ç¨¿æ—¥æ™‚"
            })
            st.caption(f"{selected_src}: {len(df_src_posts)}ä»¶")
            st.dataframe(df_src_posts, use_container_width=True, height=400, hide_index=True)
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ============================================================
# TAB4: æŠ•ç¨¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
# ============================================================
with tab4:
    st.header("æŠ•ç¨¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")

    if total > 0:
        conn = get_conn()
        df_all = pd.read_sql("SELECT text, likes, retweets, date FROM posts", conn)
        conn.close()

        df_all["char_count"] = df_all["text"].str.len()
        df_all["date_parsed"] = to_naive_datetime(df_all["date"])
        df_all["hour"] = df_all["date_parsed"].dt.hour
        df_all["weekday"] = df_all["date_parsed"].dt.dayofweek

        col_a, col_b = st.columns(2)

        with col_a:
            st.subheader("æ™‚é–“å¸¯åˆ¥ å¹³å‡ã„ã„ã­æ•°")
            df_hour = df_all.dropna(subset=["hour"]).copy()
            if len(df_hour) > 0:
                # 0ã€œ23ã®å…¨æ™‚é–“å¸¯ã‚’ç”¨æ„ã—ã¦reindexã§å¼·åˆ¶æ˜‡é †
                hour_avg = df_hour.groupby("hour")["likes"].mean().round(1)
                hour_avg = hour_avg.reindex(range(24), fill_value=0).reset_index()
                hour_avg.columns = ["æ™‚é–“å¸¯_num", "å¹³å‡ã„ã„ã­"]
                hour_avg["æ™‚é–“å¸¯"] = hour_avg["æ™‚é–“å¸¯_num"].astype(str) + "æ™‚"
                fig = px.bar(hour_avg, x="æ™‚é–“å¸¯", y="å¹³å‡ã„ã„ã­",
                             category_orders={"æ™‚é–“å¸¯": hour_avg["æ™‚é–“å¸¯"].tolist()})
                fig.update_xaxes(tickangle=0)
                fig.update_layout(margin=dict(t=20, b=20))
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        with col_b:
            st.subheader("æ›œæ—¥åˆ¥ å¹³å‡ã„ã„ã­æ•°")
            df_wd = df_all.dropna(subset=["weekday"]).copy()
            if len(df_wd) > 0:
                wd_names = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
                df_wd["æ›œæ—¥"] = df_wd["weekday"].apply(lambda x: wd_names[int(x)])
                wd_avg = df_wd.groupby("æ›œæ—¥")["likes"].mean().round(1).reindex(wd_names, fill_value=0).reset_index()
                wd_avg.columns = ["æ›œæ—¥", "å¹³å‡ã„ã„ã­"]
                fig = px.bar(wd_avg, x="æ›œæ—¥", y="å¹³å‡ã„ã„ã­",
                             category_orders={"æ›œæ—¥": wd_names})
                fig.update_xaxes(tickangle=0)
                fig.update_layout(margin=dict(t=20, b=20))
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        st.subheader("æ–‡å­—æ•°å¸¯åˆ¥ å¹³å‡ã„ã„ã­æ•°")
        bins = [0, 50, 100, 140, 200, 280, 1000]
        labels = ["ã€œ50å­—", "51-100å­—", "101-140å­—", "141-200å­—", "201-280å­—", "281å­—ã€œ"]
        df_all["æ–‡å­—æ•°å¸¯"] = pd.cut(df_all["char_count"], bins=bins, labels=labels, right=True)
        char_avg = df_all.groupby("æ–‡å­—æ•°å¸¯", observed=True)["likes"].agg(["mean", "count"]).round(1).reset_index()
        char_avg.columns = ["æ–‡å­—æ•°å¸¯", "å¹³å‡ã„ã„ã­", "æŠ•ç¨¿æ•°"]
        st.dataframe(char_avg, use_container_width=True, hide_index=True)
        fig = px.bar(char_avg, x="æ–‡å­—æ•°å¸¯", y="å¹³å‡ã„ã„ã­",
                     category_orders={"æ–‡å­—æ•°å¸¯": labels})
        fig.update_xaxes(tickangle=0)
        fig.update_layout(margin=dict(t=20, b=20))
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ============================================================
# TAB5: ã‚¹ã‚³ã‚¢è¨ºæ–­
# ============================================================
with tab5:
    st.header("æŠ•ç¨¿ã‚¹ã‚³ã‚¢è¨ºæ–­")

    input_text = st.text_area(
        "æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        height=130,
        placeholder="ã“ã“ã«æŠ•ç¨¿æ–‡ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„..."
    )

    if input_text.strip():
        v1_result = calculate_buzz_score(input_text)
        v2_result = calculate_buzz_score_v2(input_text)

        col1, col2, col3 = st.columns(3)
        col1.metric("v1ã‚¹ã‚³ã‚¢", f"{v1_result['total_score']}ç‚¹")
        col2.metric("v2ã‚¹ã‚³ã‚¢", f"{v2_result['total_score']}ç‚¹")
        col3.metric("æ–‡å­—æ•°", f"{len(input_text)}å­—")

        col_left, col_right = st.columns(2)
        with col_left:
            st.subheader("v2 è¦ç´ åˆ¥ã‚¹ã‚³ã‚¢")
            st.dataframe(
                pd.DataFrame([{"è¦ç´ ": k, "å¾—ç‚¹": v} for k, v in v2_result["factors"].items()]),
                use_container_width=True, hide_index=True
            )
        with col_right:
            st.subheader("v1 è¦ç´ åˆ¥ã‚¹ã‚³ã‚¢")
            st.dataframe(
                pd.DataFrame([{"è¦ç´ ": k, "å¾—ç‚¹": v} for k, v in v1_result["factors"].items()]),
                use_container_width=True, hide_index=True
            )

        st.subheader("æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
        advice = []
        text_len = len(input_text)
        if text_len < 80:
            advice.append("æ–‡å­—æ•°ãŒå°‘ãªã‚ã§ã™ã€‚80ã€œ140å­—ãŒæœ€ã‚‚ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãŒé«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
        elif text_len > 280:
            advice.append("æ–‡å­—æ•°ãŒå¤šã‚ã§ã™ã€‚280å­—ä»¥å†…ã«åã‚ã‚‹ã¨èª­ã¾ã‚Œã‚„ã™ããªã‚Šã¾ã™ã€‚")
        if "ï¼" not in input_text and "!" not in input_text:
            advice.append("æ„Ÿæƒ…ã‚’å¼·èª¿ã™ã‚‹ã€Œï¼ã€ã‚’è¿½åŠ ã™ã‚‹ã¨åå¿œãŒä¸ŠãŒã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
        if not any(kw in input_text for kw in ["æ­£ç›´", "å®Ÿã¯", "ãƒ‰ç´ äºº", "å‘Šç™½", "æœ¬å½“ã®ã“ã¨"]):
            advice.append("ã€Œæ­£ç›´ã€ã€Œå®Ÿã¯ã€ã€Œãƒ‰ç´ äººã€ãªã©è‡ªå·±é–‹ç¤ºãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å…¥ã‚Œã‚‹ã¨ãƒã‚ºã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚")
        if not any(kw in input_text for kw in ["ï¼Ÿ", "?", "ã©ã†æ€", "ã‚ãªãŸ"]):
            advice.append("ç–‘å•å½¢ã‚„èª­è€…ã¸ã®å•ã„ã‹ã‘ã‚’å…¥ã‚Œã‚‹ã¨ãƒªãƒ—ãƒ©ã‚¤ãŒå¢—ãˆã¾ã™ã€‚")
        if v2_result["total_score"] >= 70:
            advice.append("ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã§ã™ã€‚ã“ã®ã¾ã¾æŠ•ç¨¿ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
        elif v2_result["total_score"] >= 50:
            advice.append("ã‚¹ã‚³ã‚¢ã¯ä¸­ç¨‹åº¦ã§ã™ã€‚ä¸Šè¨˜ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å‚è€ƒã«ç£¨ã„ã¦ã¿ã¦ãã ã•ã„ã€‚")
        else:
            advice.append("ã‚¹ã‚³ã‚¢ãŒä½ã‚ã§ã™ã€‚æ‹“å·³ã®æ–¹ç¨‹å¼ï¼ˆç­‰èº«å¤§ã®å‘Šç™½Ã—å…·ä½“çš„ä½“é¨“ï¼‰ã‚’æ„è­˜ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
        for a in advice:
            st.write(f"- {a}")

        st.subheader("ã“ã®æŠ•ç¨¿ã«è¿‘ã„ãƒã‚ºæŠ•ç¨¿ TOP3")
        if total > 0:
            conn = get_conn()
            df_buzz = pd.read_sql(
                "SELECT account, text, likes, retweets FROM posts ORDER BY likes DESC LIMIT 200",
                conn
            )
            conn.close()
            words = set(input_text.replace("ã€‚", " ").replace("ã€", " ").split())
            df_buzz["é¡ä¼¼åº¦"] = df_buzz["text"].apply(
                lambda t: len(words & set(str(t).replace("ã€‚", " ").replace("ã€", " ").split()))
            )
            top3 = df_buzz.sort_values(["é¡ä¼¼åº¦", "likes"], ascending=[False, False]).head(3)
            for i, (_, row) in enumerate(top3.iterrows(), 1):
                with st.expander(f"#{i} ã„ã„ã­{row['likes']}ä»¶ / {row['account']}"):
                    st.write(row["text"])

# ============================================================
# TAB6: ã‚¹ã‚³ã‚¢ç²¾åº¦æ¨ç§»
# ============================================================
with tab6:
    st.header("ã‚¹ã‚³ã‚¢ç²¾åº¦ã®æ¨ç§»")

    conn = get_conn()
    df_history = pd.read_sql(
        "SELECT version, correlation, sample_size, date FROM score_history ORDER BY date DESC",
        conn
    )
    conn.close()

    if len(df_history) > 0:
        df_history["date"] = pd.to_datetime(df_history["date"]).dt.strftime("%Y/%m/%d %H:%M")
        df_history = df_history.rename(columns={
            "version": "ãƒãƒ¼ã‚¸ãƒ§ãƒ³", "correlation": "ç›¸é–¢ä¿‚æ•°",
            "sample_size": "ã‚µãƒ³ãƒ—ãƒ«æ•°", "date": "è¨ˆç®—æ—¥æ™‚",
        })
        st.dataframe(df_history, use_container_width=True, hide_index=True)
    else:
        st.info("ã‚¹ã‚³ã‚¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `python recalculate_score.py` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# ============================================================
# TAB7: é‡è¤‡ç®¡ç†
# ============================================================
with tab7:
    st.header("é‡è¤‡ç®¡ç†")
    st.caption("åˆ¤å®šåŸºæº–: åŒä¸€ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ + åŒä¸€ãƒ†ã‚­ã‚¹ãƒˆå…¨æ–‡")

    conn = get_conn()
    dup_groups = conn.execute("""
        SELECT
            account,
            text,
            COUNT(*) as cnt,
            MIN(id) as keep_id,
            MAX(likes) as max_likes
        FROM posts
        GROUP BY account, text
        HAVING cnt > 1
        ORDER BY cnt DESC
    """).fetchall()
    dup_total = sum(r[2] - 1 for r in dup_groups)
    conn.close()

    if dup_groups:
        st.warning(f"é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—: {len(dup_groups)}ä»¶ / å‰Šé™¤å¯èƒ½ãªé‡è¤‡æŠ•ç¨¿: {dup_total}ä»¶")

        col_btn1, col_btn2 = st.columns([1, 3])
        with col_btn1:
            if st.button(f"å…¨é‡è¤‡ã‚’ä¸€æ‹¬å‰Šé™¤ï¼ˆ{dup_total}ä»¶å‰Šé™¤ï¼‰", type="primary"):
                conn = get_conn()
                before = conn.execute("SELECT COUNT(*) FROM posts").fetchone()[0]
                conn.execute("""
                    DELETE FROM posts
                    WHERE id NOT IN (
                        SELECT MIN(id) FROM posts GROUP BY account, text
                    )
                """)
                conn.commit()
                after = conn.execute("SELECT COUNT(*) FROM posts").fetchone()[0]
                conn.close()
                st.success(f"å‰Šé™¤å®Œäº†: {before - after}ä»¶å‰Šé™¤ / æ®‹ã‚Š{after}ä»¶")
                st.rerun()

        st.divider()
        st.subheader("é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—ä¸€è¦§")

        for i, (account, text, cnt, keep_id, max_likes) in enumerate(dup_groups):
            label = f"[{cnt}ä»¶é‡è¤‡] {account} / ã€Œ{text[:40]}...ã€ / ã„ã„ã­æœ€å¤§{max_likes}"
            with st.expander(label):
                conn = get_conn()
                group_rows = conn.execute(
                    "SELECT id, account, text, likes, date, source_file FROM posts "
                    "WHERE account=? AND text=? ORDER BY id ASC",
                    (account, text)
                ).fetchall()
                conn.close()

                df_group = pd.DataFrame(
                    group_rows, columns=["ID", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "æœ¬æ–‡", "ã„ã„ã­", "æŠ•ç¨¿æ—¥æ™‚", "ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«"]
                )
                df_group["æœ¬æ–‡"] = df_group["æœ¬æ–‡"].str[:60]
                df_group["æ®‹ã™"] = df_group["ID"] == keep_id
                st.dataframe(df_group, use_container_width=True, hide_index=True)

                if st.button(f"ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®é‡è¤‡ã‚’å‰Šé™¤ï¼ˆ{cnt - 1}ä»¶å‰Šé™¤ã€ID:{keep_id}ã‚’æ®‹ã™ï¼‰", key=f"del_{i}"):
                    conn = get_conn()
                    conn.execute(
                        "DELETE FROM posts WHERE account=? AND text=? AND id != ?",
                        (account, text, keep_id)
                    )
                    conn.commit()
                    conn.close()
                    st.success(f"{cnt - 1}ä»¶å‰Šé™¤ã—ã¾ã—ãŸ")
                    st.rerun()
    else:
        st.success("é‡è¤‡æŠ•ç¨¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

# ============================================================
# TAB8: æŠ•ç¨¿ä½œæˆ
# ============================================================
with tab8:
    st.header("æŠ•ç¨¿ä½œæˆ")

    # DBã‹ã‚‰ãƒã‚ºæŠ•ç¨¿TOPå–å¾—ï¼ˆå…±é€šåˆ©ç”¨ï¼‰
    conn = get_conn()
    top_posts = pd.read_sql(
        "SELECT text, likes, account FROM posts WHERE likes > 0 ORDER BY likes DESC LIMIT 20",
        conn
    )
    conn.close()

    # ============================================================
    # 1. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§
    # ============================================================
    st.subheader("1. æŠ•ç¨¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")

    TEMPLATES = [
        {
            "name": "æ‹“å·³å‹ï¼ˆè‡ªå·±é–‹ç¤ºå‹ï¼‰",
            "structure": "è‡ªå·±é–‹ç¤º â†’ å…·ä½“çš„ä½“é¨“ â†’ æ°—ã¥ã â†’ ä½™éŸ»",
            "description": "ã€Œæ­£ç›´ã«è¨€ã†ã€ã€Œå®Ÿã¯ã€ç³»ã®å‘Šç™½ã‹ã‚‰å…¥ã‚Šã€å…·ä½“çš„ãªä½“é¨“ã‚’èªã‚Šã€é™ã‹ãªæ°—ã¥ãã§ç· ã‚ã‚‹ã€‚CTAãªã—ã€‚",
            "skeleton": (
                "æ­£ç›´ã«è¨€ã†ã€‚[è‡ªå·±é–‹ç¤ºï¼šæ¥ãšã‹ã—ã„ã“ã¨ãƒ»å¼±ç‚¹ãƒ»å¤±æ•—]\n\n"
                "[å…·ä½“çš„ãªä½“é¨“ãƒ»æ•°å­—ãƒ»ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰]\n\n"
                "ãã‚Œã§æ°—ã¥ã„ãŸã®ã¯ã€[ã‚·ãƒ³ãƒ—ãƒ«ãªæ°—ã¥ã]ã€‚\n\n"
                "[ä½™éŸ»ã®ã‚ã‚‹ä¸€æ–‡ã§ç· ã‚ã€‚å•ã„ã‹ã‘ã§ã‚‚å¯]"
            ),
            "keywords": ["æ­£ç›´", "å®Ÿã¯", "ãƒ‰ç´ äºº", "å‘Šç™½", "æ¥ãšã‹ã—ã„"],
        },
        {
            "name": "ãƒªã‚¹ã‚¯è­¦å‘Šå‹",
            "structure": "äº‹å®Ÿæç¤º â†’ é©šã â†’ å¯¾å‡¦æ³•",
            "description": "ã€ŒçŸ¥ã‚‰ãªã„ã¨æã™ã‚‹ã€ã€Œâ—‹â—‹ã—ã¦ã‚‹äººã¯æ³¨æ„ã€ç³»ã€‚å…·ä½“çš„ãªæ•°å­—ã§é©šã‹ã›ã¦ã€å¯¾å‡¦æ³•ã‚’æç¤ºã€‚",
            "skeleton": (
                "[æ„å¤–ãªäº‹å®Ÿãƒ»çµ±è¨ˆãƒ»ä½“é¨“]\n\n"
                "ã“ã‚Œã€å®Ÿã¯[é©šãã®ãƒã‚¤ãƒ³ãƒˆ]ã€‚\n\n"
                "å¯¾å‡¦æ³•ã¯[å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³]ã ã‘ã€‚\n\n"
                "[ä¸€è¨€ã§ç· ã‚]"
            ),
            "keywords": ["æ³¨æ„", "çŸ¥ã‚‰ãªã„ã¨", "æ", "å®Ÿã¯", "å±ãªã„"],
        },
        {
            "name": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ãƒ„ãƒ¼ãƒ«ç´¹ä»‹å‹",
            "structure": "å¤±æ•— â†’ æ”¹å–„ â†’ å…·ä½“ä¾‹",
            "description": "ã€Œã“ã†ä½¿ã£ãŸã‚‰å¤±æ•—ã—ãŸã€â†’ã€Œã“ã†å¤‰ãˆãŸã‚‰ä¸Šæ‰‹ãã„ã£ãŸã€â†’ å…·ä½“çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/æ‰‹é †ã‚’æç¤ºã€‚",
            "skeleton": (
                "[æœ€åˆã«ã‚„ã£ãŸå¤±æ•—ãƒ»ã‚ˆãã‚ã‚‹é–“é•ã„]\n\n"
                "ã§ã‚‚[æ”¹å–„ã—ãŸã“ã¨]ã‚’ã—ãŸã‚‰å…¨ç„¶é•ã£ãŸã€‚\n\n"
                "å…·ä½“çš„ã«ã¯ï¼š\n[ç®‡æ¡æ›¸ãã§æ‰‹é †ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹]\n\n"
                "[å†ç¾æ€§ã‚ã‚‹ç· ã‚ãƒ»ã€Œè©¦ã—ã¦ã¿ã¦ã€ã§ã‚‚å¯]"
            ),
            "keywords": ["ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", "Claude", "ChatGPT", "è©¦ã—ãŸ", "å¤‰ãˆãŸ"],
        },
    ]

    # DBã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¥ã®ä¾‹ç¤ºæŠ•ç¨¿ã‚’å–å¾—
    def find_template_examples(keywords, df, n=2):
        if df.empty:
            return []
        mask = df["text"].apply(
            lambda t: any(kw in str(t) for kw in keywords)
        )
        matched = df[mask].head(n)
        return matched[["text", "likes", "account"]].to_dict("records")

    for tmpl in TEMPLATES:
        with st.expander(f"**{tmpl['name']}** â”€ {tmpl['structure']}"):
            col_l, col_r = st.columns([1, 1])
            with col_l:
                st.markdown(f"**æ§‹é€ èª¬æ˜**\n\n{tmpl['description']}")
                st.code(tmpl["skeleton"], language=None)
            with col_r:
                examples = find_template_examples(tmpl["keywords"], top_posts)
                if examples:
                    st.markdown("**DBå†…ã®é¡ä¼¼ãƒã‚ºæŠ•ç¨¿ï¼ˆã„ã„ã­é †ï¼‰**")
                    for ex in examples:
                        st.info(f"ã„ã„ã­ {ex['likes']}ä»¶ / {ex['account']}\n\n{ex['text'][:120]}{'...' if len(ex['text'])>120 else ''}")
                else:
                    st.caption("è©²å½“ã™ã‚‹ä¾‹ãŒDBã«ã‚ã‚Šã¾ã›ã‚“")

    st.divider()

    # ============================================================
    # 2. ãƒã‚ºè¦ç´ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
    # ============================================================
    st.subheader("2. ãƒã‚ºè¦ç´ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ")

    draft = st.text_area(
        "ä¸‹æ›¸ãã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„",
        height=150,
        placeholder="ã“ã“ã«æŠ•ç¨¿ã®ä¸‹æ›¸ãã‚’è²¼ã‚Šä»˜ã‘ã‚‹ã¨è‡ªå‹•ãƒã‚§ãƒƒã‚¯ã—ã¾ã™...",
        key="draft_check"
    )

    if draft.strip():
        checks = []

        # ç§˜åŒ¿æ„Ÿãƒ•ãƒ¬ãƒ¼ã‚º
        secret_phrases = ["æ­£ç›´", "å®Ÿã¯", "ãƒ‰ç´ äºº", "å‘Šç™½", "æœ¬å½“ã®ã“ã¨", "æ¥ãšã‹ã—ã„", "è¨€ãˆãªã‹ã£ãŸ", "åˆã‚ã¦è¨€ã†", "ã“ã“ã ã‘ã®"]
        has_secret = any(p in draft for p in secret_phrases)
        checks.append(("ç§˜åŒ¿æ„Ÿãƒ•ãƒ¬ãƒ¼ã‚º", has_secret,
                        f"ã‚ã‚Šï¼ˆ{next(p for p in secret_phrases if p in draft)}ï¼‰" if has_secret else "ãªã— â”€ ã€Œæ­£ç›´ã€ã€Œå®Ÿã¯ã€ã€Œãƒ‰ç´ äººã€ãªã©ã‚’è¿½åŠ æ¨å¥¨"))

        # å…·ä½“çš„ãªæ•°å­—ãƒ»å›ºæœ‰åè©
        import re
        has_number = bool(re.search(r'\d+', draft))
        checks.append(("å…·ä½“çš„ãªæ•°å­—", has_number,
                        "ã‚ã‚Š" if has_number else "ãªã— â”€ æ•°å­—ã‚’å…¥ã‚Œã‚‹ã¨ä¿¡é ¼æ„ŸUP"))

        # CTAï¼ˆè¡Œå‹•å–šèµ·ï¼‰
        cta_phrases = ["ãƒ•ã‚©ãƒ­ãƒ¼", "ã„ã„ã­", "RT", "ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ", "ã‚·ã‚§ã‚¢", "ä¿å­˜", "ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯", "ã‚³ãƒ¡ãƒ³ãƒˆ", "æ‹¡æ•£"]
        has_cta = any(p in draft for p in cta_phrases)
        checks.append(("CTAãªã—", not has_cta,
                        "å•é¡Œãªã—" if not has_cta else f"CTAæ¤œå‡ºï¼šã€Œ{next(p for p in cta_phrases if p in draft)}ã€â”€ å‰Šé™¤æ¨å¥¨ï¼ˆCTAãªã—ã®æ–¹ãŒãƒã‚ºã‚Šã‚„ã™ã„ï¼‰"))

        # çµµæ–‡å­—
        emoji_pattern = re.compile(
            "[\U0001F300-\U0001FAFF\U00002700-\U000027BF\U0000FE00-\U0000FEFF]", re.UNICODE
        )
        has_emoji = bool(emoji_pattern.search(draft))
        checks.append(("çµµæ–‡å­—ãªã—", not has_emoji,
                        "å•é¡Œãªã—" if not has_emoji else "çµµæ–‡å­—æ¤œå‡º â”€ æ‹“å·³ã‚¹ã‚¿ã‚¤ãƒ«ã¯çµµæ–‡å­—ãªã—ãŒåŸºæœ¬"))

        # æ–‡å­—æ•°
        char_len = len(draft)
        good_len = 130 <= char_len <= 170
        checks.append(("æ–‡å­—æ•°130-170å­—", good_len,
                        f"{char_len}å­—ï¼ˆæœ€é©ç¯„å›²å†…ï¼‰" if good_len else f"{char_len}å­— â”€ {'çŸ­ã„ï¼ˆ+{130-char_len}å­—æ¨å¥¨ï¼‰' if char_len < 130 else 'é•·ã„ï¼ˆ{char_len-170}å­—å‰Šæ¸›æ¨å¥¨ï¼‰'}"))

        passed = sum(1 for _, ok, _ in checks if ok)
        st.metric("ãƒã‚§ãƒƒã‚¯çµæœ", f"{passed} / {len(checks)} é€šé")

        for label, ok, detail in checks:
            icon = "âœ…" if ok else "âš ï¸"
            st.write(f"{icon} **{label}** â”€ {detail}")

    st.divider()

    # ============================================================
    # 3. Claudeã«è²¼ã‚‹ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªå‹•ç”Ÿæˆ
    # ============================================================
    st.subheader("3. Claudeç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªå‹•ç”Ÿæˆ")

    col_p1, col_p2 = st.columns(2)
    with col_p1:
        selected_tmpl = st.selectbox(
            "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é¸æŠ",
            [t["name"] for t in TEMPLATES],
            key="prompt_tmpl"
        )
    with col_p2:
        keywords_input = st.text_input(
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ†ãƒ¼ãƒï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
            placeholder="ä¾‹: Claude, ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ, å¤±æ•—è«‡",
            key="prompt_kw"
        )

    tone_note = st.text_area(
        "è£œè¶³ãƒ»ãƒˆãƒ¼ãƒ³æŒ‡å®šï¼ˆä»»æ„ï¼‰",
        placeholder="ä¾‹: è‡ªè™çš„ã«ã€18-21æ™‚æŠ•ç¨¿å‘ã‘ã€ã‚µãƒ©ãƒªãƒ¼ãƒãƒ³å‘ã‘",
        height=70,
        key="prompt_tone"
    )

    # ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ãŸã³ã«æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    if "prompt_gen_count" not in st.session_state:
        st.session_state["prompt_gen_count"] = 0

    if st.button("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ", type="primary", key="gen_prompt"):
        with st.spinner("ç”Ÿæˆä¸­..."):
            tmpl_info = next(t for t in TEMPLATES if t["name"] == selected_tmpl)

            top5_features = ""
            if not top_posts.empty:
                top5_lines = []
                for _, r in top_posts.head(5).iterrows():
                    top5_lines.append(f"ãƒ»ã„ã„ã­{r['likes']}ä»¶: {str(r['text'])[:80]}{'...' if len(str(r['text']))>80 else ''}")
                top5_features = "\n".join(top5_lines)

            kw_str = keywords_input.strip() if keywords_input.strip() else "ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœªå…¥åŠ›ï¼‰"
            tone_str = f"\nè£œè¶³: {tone_note.strip()}" if tone_note.strip() else ""

            prompt = f"""ä»¥ä¸‹ã®æ¡ä»¶ã§ãƒã‚¹ãƒˆã‚’3ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œã£ã¦ï¼š

ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘{tmpl_info['name']}
æ§‹é€ : {tmpl_info['structure']}

ã€ãƒ†ãƒ¼ãƒãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‘
{kw_str}{tone_str}

ã€åˆ¶ç´„æ¡ä»¶ã€‘
- æ–‡å­—æ•°: 130ã€œ170å­—
- CTAï¼ˆãƒ•ã‚©ãƒ­ãƒ¼/ã„ã„ã­/RTï¼‰ãªã—
- çµµæ–‡å­—ãªã—
- ã€Œæ­£ç›´ã€ã€Œå®Ÿã¯ã€ã€Œãƒ‰ç´ äººã€ãªã©ã®è‡ªå·±é–‹ç¤ºãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å…¥ã‚Œã‚‹
- å…·ä½“çš„ãªæ•°å­—ã‚„å›ºæœ‰åè©ã‚’ä½¿ã†
- ä½™éŸ»ã§çµ‚ã‚ã‚‹ï¼ˆå•ã„ã‹ã‘ã§ã‚‚å¯ï¼‰

ã€å‚è€ƒ: DBå†…ãƒã‚ºæŠ•ç¨¿TOP5ï¼ˆã„ã„ã­é †ï¼‰ã€‘
{top5_features}

ä¸Šè¨˜ã®å‚è€ƒæŠ•ç¨¿ã®ãƒˆãƒ¼ãƒ³ãƒ»æ§‹é€ ã‚’å‚è€ƒã«ã€3ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆã—ã¦ã€‚
å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã€Œãªãœã“ã®æ§‹é€ ã«ã—ãŸã‹ã€ã‚’1è¡Œã§æ·»ãˆã¦ãã ã•ã„ã€‚"""

            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—ã‚„ã—ã¦widgetã‚­ãƒ¼ã‚’å¤‰ãˆã€æ¯å›ãƒ•ãƒ¬ãƒƒã‚·ãƒ¥è¡¨ç¤º
            st.session_state["prompt_gen_count"] += 1
            st.session_state["generated_prompt"] = prompt

    if "generated_prompt" in st.session_state:
        prompt_text = st.session_state["generated_prompt"]

        # st.code ã§ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯å…¨é¸æŠã‚³ãƒ”ãƒ¼
        st.markdown("**ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**ï¼ˆå³ä¸Šã®ã‚³ãƒ”ãƒ¼ã‚¢ã‚¤ã‚³ãƒ³ã§ã‚³ãƒ”ãƒ¼ï¼‰")
        st.code(prompt_text, language=None)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        st.download_button(
            label="ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=prompt_text.encode("utf-8"),
            file_name="claude_prompt.txt",
            mime="text/plain",
        )

# ============================================================
# TAB9: èª­è€…å¿ƒç†åˆ†æ
# ============================================================
with tab9:
    st.header("èª­è€…å¿ƒç†åˆ†æ")
    st.caption("æŠ•ç¨¿ã‚’èª­ã‚“ã èª­è€…ãŒãªãœã„ã„ã­/RT/ãƒªãƒ—/ãƒ–ã‚¯ãƒ/ãƒ•ã‚©ãƒ­ãƒ¼ã—ãŸã‹ã€å¿ƒç†ã‚’è¨€èªåŒ–ã™ã‚‹")

    # ---- 1. å˜ä½“æŠ•ç¨¿åˆ†æ ----
    st.subheader("1. æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æ")

    # DBã‹ã‚‰é¸æŠã—ãŸå€¤ã‚’ã€ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆç”Ÿæˆå‰ã«ã‚»ãƒƒãƒˆï¼ˆã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆkeyã¸ã®ç›´æ¥ä»£å…¥ã‚’ã“ã“ã§è¡Œã†ï¼‰
    if "psych_text_preload" in st.session_state:
        st.session_state["psych_text"] = st.session_state.pop("psych_text_preload")
        st.session_state["psych_likes"] = st.session_state.pop("psych_likes_preload", 0)
        st.session_state["psych_rt"] = st.session_state.pop("psych_rt_preload", 0)
        st.session_state["psych_rep"] = st.session_state.pop("psych_rep_preload", 0)

    col_psych_l, col_psych_r = st.columns([2, 1])
    with col_psych_l:
        psych_text = st.text_area(
            "æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›",
            height=120,
            key="psych_text",
            placeholder="æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„..."
        )
    with col_psych_r:
        psych_likes = st.number_input("ã„ã„ã­æ•°ï¼ˆå‚è€ƒå€¤ï¼‰", min_value=0, value=0, step=10, key="psych_likes")
        psych_rt = st.number_input("RTæ•°", min_value=0, value=0, step=1, key="psych_rt")
        psych_rep = st.number_input("ãƒªãƒ—ãƒ©ã‚¤æ•°", min_value=0, value=0, step=1, key="psych_rep")

    # DBã‹ã‚‰æŠ•ç¨¿ã‚’é¸æŠã—ã¦å…¥åŠ›æ¬„ã‚’è£œå®Œ
    if total > 0:
        with st.expander("ã¾ãŸã¯DBã®æŠ•ç¨¿ã‹ã‚‰é¸æŠ"):
            conn = get_conn()
            df_psych_sample = pd.read_sql(
                "SELECT account, text, likes, retweets, replies FROM posts ORDER BY likes DESC LIMIT 50",
                conn
            )
            conn.close()
            sel_opts = [
                f"ã„ã„ã­{r['likes']}ä»¶ @{r['account']}: {r['text'][:40]}..."
                for _, r in df_psych_sample.iterrows()
            ]
            sel_idx = st.selectbox(
                "æŠ•ç¨¿ã‚’é¸æŠ", range(len(sel_opts)),
                format_func=lambda i: sel_opts[i], key="psych_sel"
            )
            if st.button("ã“ã®æŠ•ç¨¿ã‚’ä¸Šã®å…¥åŠ›æ¬„ã«åæ˜ ", key="psych_from_db"):
                row = df_psych_sample.iloc[sel_idx]
                # preloadã‚­ãƒ¼ã«æ›¸ãè¾¼ã¿ â†’ rerunå¾Œã«ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆç”Ÿæˆå‰ã§å‡¦ç†
                st.session_state["psych_text_preload"] = row["text"]
                st.session_state["psych_likes_preload"] = int(row["likes"])
                st.session_state["psych_rt_preload"] = int(row["retweets"])
                st.session_state["psych_rep_preload"] = int(row["replies"])
                st.rerun()

    if psych_text.strip():
        result = analyze_reader_psychology(psych_text, psych_likes, psych_rt, psych_rep)

        col_m1, col_m2, col_m3 = st.columns(3)
        col_m1.metric("èª­è€…ã®ç¬¬ä¸€æ„Ÿæƒ…", result["primary_emotion"])
        col_m2.metric("Grokãƒˆãƒ¼ãƒ³è©•ä¾¡", result["tone"])
        col_m3.metric("ãªãœãƒã‚ºã£ãŸã‹", "â†“ç¢ºèª")

        st.info(f"**åˆ†æã‚µãƒãƒªãƒ¼:** {result['one_line_why']}")

        col_tl, col_tr = st.columns(2)
        with col_tl:
            if result["like_triggers"]:
                st.markdown("**â¤ï¸ ã„ã„ã­ã®å¿ƒç†**")
                for t in result["like_triggers"]:
                    st.write(f"â€¢ **{t['trigger']}**")
                    st.caption(f"  â†’ {t['psychology']}")

            if result["rt_triggers"]:
                st.markdown("**ğŸ” RTã®å¿ƒç†**")
                for t in result["rt_triggers"]:
                    st.write(f"â€¢ **{t['trigger']}**")
                    st.caption(f"  â†’ {t['psychology']}")

        with col_tr:
            if result["reply_triggers"]:
                st.markdown("**ğŸ’¬ ãƒªãƒ—ãƒ©ã‚¤ã®å¿ƒç†**")
                for t in result["reply_triggers"]:
                    st.write(f"â€¢ **{t['trigger']}**")
                    st.caption(f"  â†’ {t['psychology']}")

            if result["bookmark_triggers"]:
                st.markdown("**ğŸ”– ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯è¦å› **")
                for t in result["bookmark_triggers"]:
                    st.write(f"â€¢ **{t['trigger']}**")
                    st.caption(f"  â†’ {t['psychology']}")

            if result["follow_triggers"]:
                st.markdown("**ğŸ‘¤ ãƒ•ã‚©ãƒ­ãƒ¼è¦å› **")
                for t in result["follow_triggers"]:
                    st.write(f"â€¢ **{t['trigger']}**")
                    st.caption(f"  â†’ {t['psychology']}")

        if not any([result["like_triggers"], result["rt_triggers"], result["reply_triggers"]]):
            st.warning("æ˜ç¢ºãªãƒˆãƒªã‚¬ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚æ‹“å·³ã®æ–¹ç¨‹å¼ï¼ˆç­‰èº«å¤§ã®å‘Šç™½Ã—å…·ä½“çš„ä½“é¨“ï¼‰ã‚’æ„è­˜ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")

    st.divider()

    # ---- 2. DBå…¨ä½“ã®å¿ƒç†ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆ ----
    st.subheader("2. DBå…¨ä½“ã®å¿ƒç†ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆï¼ˆä¸Šä½100ä»¶ï¼‰")

    if total > 0:
        if st.button("çµ±è¨ˆã‚’è¡¨ç¤º", key="psych_stats_btn"):
            conn = get_conn()
            df_psych_db = pd.read_sql(
                "SELECT text, likes, retweets, replies FROM posts WHERE likes > 0 ORDER BY likes DESC LIMIT 100",
                conn
            )
            conn.close()

            with st.spinner("100ä»¶ã‚’åˆ†æä¸­..."):
                all_psych = [
                    analyze_reader_psychology(
                        str(r["text"] or ""),
                        int(r["likes"] or 0),
                        int(r["retweets"] or 0),
                        int(r["replies"] or 0),
                    )
                    for _, r in df_psych_db.iterrows()
                ]
                likes_list = df_psych_db["likes"].fillna(0).astype(int).tolist()

            # æ„Ÿæƒ…åˆ†å¸ƒ
            emotion_cnt = Counter(r["primary_emotion"] for r in all_psych)
            emotion_likes_map = {}
            for r, lk in zip(all_psych, likes_list):
                emotion_likes_map.setdefault(r["primary_emotion"], []).append(lk)
            df_emotion = pd.DataFrame([
                {
                    "æ„Ÿæƒ…": e,
                    "å‡ºç¾æ•°": c,
                    "å¹³å‡ã„ã„ã­": round(sum(emotion_likes_map[e]) / len(emotion_likes_map[e])),
                }
                for e, c in emotion_cnt.most_common()
            ])

            col_e1, col_e2 = st.columns(2)
            with col_e1:
                st.markdown("**èª­è€…ã®ç¬¬ä¸€æ„Ÿæƒ… åˆ†å¸ƒ**")
                st.dataframe(df_emotion, use_container_width=True, hide_index=True)
            with col_e2:
                fig_e = px.bar(df_emotion, x="æ„Ÿæƒ…", y="å¹³å‡ã„ã„ã­", title="æ„Ÿæƒ…åˆ¥ å¹³å‡ã„ã„ã­")
                fig_e.update_layout(margin=dict(t=30, b=20))
                st.plotly_chart(fig_e, use_container_width=True)

            # ã„ã„ã­ãƒˆãƒªã‚¬ãƒ¼åˆ†å¸ƒ
            like_trigger_cnt = Counter(
                t["trigger"] for r in all_psych for t in r["like_triggers"]
            )
            like_trigger_likes = {}
            for r, lk in zip(all_psych, likes_list):
                for t in r["like_triggers"]:
                    like_trigger_likes.setdefault(t["trigger"], []).append(lk)

            if like_trigger_cnt:
                df_like_trg = pd.DataFrame([
                    {
                        "ãƒˆãƒªã‚¬ãƒ¼": t,
                        "å‡ºç¾æ•°": c,
                        "å¹³å‡ã„ã„ã­": round(sum(like_trigger_likes[t]) / len(like_trigger_likes[t])),
                    }
                    for t, c in like_trigger_cnt.most_common()
                ])
                st.markdown("**ã„ã„ã­ãƒˆãƒªã‚¬ãƒ¼ å‡ºç¾é »åº¦ï¼ˆä¸Šä½100ä»¶ä¸­ï¼‰**")
                st.dataframe(df_like_trg, use_container_width=True, hide_index=True)
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ============================================================
# TAB10: Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ†æ
# ============================================================
with tab10:
    st.header("Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ†æ")
    st.caption("Xã®å…¬é–‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆPhoenix/Grokï¼‰ã«åŸºã¥ãæŠ•ç¨¿ã‚¹ã‚³ã‚¢åˆ†æ")

    # ---- 1. å˜ä½“ã‚¹ã‚³ã‚¢è¨ºæ–­ ----
    st.subheader("1. æŠ•ç¨¿ã‚¹ã‚³ã‚¢è¨ºæ–­")

    algo_input = st.text_area(
        "æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›",
        height=120,
        key="algo_input",
        placeholder="ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘ã‚‹ã¨Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã™..."
    )
    has_premium = st.checkbox("X PremiumåŠ å…¥ï¼ˆ4å€ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰", key="algo_premium")

    if algo_input.strip():
        algo_result = calculate_algorithm_score(algo_input, has_premium=has_premium)
        early_result = predict_early_engagement(algo_input)
        tone_result = analyze_tone(algo_input)

        col_a1, col_a2, col_a3 = st.columns(3)
        col_a1.metric("Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚¹ã‚³ã‚¢", f"{algo_result['total_score']} / 100ç‚¹")
        col_a2.metric("æ—©æœŸåå¿œé€Ÿåº¦", early_result["predicted_velocity"])
        col_a3.metric(
            "Grokãƒˆãƒ¼ãƒ³è©•ä¾¡",
            tone_result["overall"],
            "Grokãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼" if tone_result["grok_friendly"] else "è¦æ”¹å–„",
        )

        FACTOR_DESCS = {
            "ãƒªãƒ—ãƒ©ã‚¤èª˜ç™ºåŠ›": "ãƒªãƒ—ãƒ©ã‚¤é‡ã¿13.5Ã—ã€‚ç–‘å•å½¢ãƒ»æ„è¦‹æ±‚ã‚ãƒ•ãƒ¬ãƒ¼ã‚ºã§åŠ ç‚¹ï¼ˆæœ€å¤§25ç‚¹ï¼‰",
            "æ»åœ¨æ™‚é–“": "2åˆ†è¶…ã§+10é‡ã¿ã€‚æ–‡å­—æ•°ãƒ»æ§‹é€ ãƒ»æ•°å­—ã§åŠ ç‚¹ï¼ˆæœ€å¤§20ç‚¹ï¼‰",
            "ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ»ä¼šè©±": "ã‚¹ãƒ¬ãƒƒãƒ‰=3å€ãƒ–ãƒ¼ã‚¹ãƒˆã€‚ä¼šè©±ã‚¯ãƒªãƒƒã‚¯é‡ã¿11.0ï¼ˆæœ€å¤§15ç‚¹ï¼‰",
            "ãƒˆãƒ¼ãƒ³": "GrokãŒãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»å»ºè¨­çš„ã‚’è©•ä¾¡ã€‚æ”»æ’ƒçš„ã¯æŠ‘åˆ¶ï¼ˆæœ€å¤§15ç‚¹ï¼‰",
            "ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯èª˜ç™º": "ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯é‡ã¿10.0ã€‚ãƒªã‚¹ãƒˆãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ»æ•°å­—ã§åŠ ç‚¹ï¼ˆæœ€å¤§10ç‚¹ï¼‰",
            "å¤–éƒ¨ãƒªãƒ³ã‚¯": "å¤–éƒ¨ãƒªãƒ³ã‚¯ã§50%ãƒªãƒ¼ãƒæ¸›ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰",
            "ãƒ—ãƒ­ãƒ•ã‚¯ãƒªãƒƒã‚¯èª˜ç™º": "ãƒ—ãƒ­ãƒ•ã‚¯ãƒªãƒƒã‚¯é‡ã¿12.0ã€‚ç§˜åŒ¿æ„Ÿãƒ»è‡ªå·±é–‹ç¤ºã§åŠ ç‚¹ï¼ˆæœ€å¤§10ç‚¹ï¼‰",
            "æ—©æœŸåå¿œæ€§": "æŠ•ç¨¿å¾Œ1æ™‚é–“ã§50%æ±ºã¾ã‚‹ã€‚å†’é ­ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã§åŠ ç‚¹ï¼ˆæœ€å¤§5ç‚¹ï¼‰",
        }

        st.subheader("è¦ç´ åˆ¥ã‚¹ã‚³ã‚¢å†…è¨³")
        df_factors = pd.DataFrame([
            {"è¦ç´ ": k, "å¾—ç‚¹": v, "èª¬æ˜": FACTOR_DESCS.get(k, "")}
            for k, v in algo_result["factors"].items()
        ])
        st.dataframe(df_factors, use_container_width=True, hide_index=True)

        # æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹
        FACTOR_MAX = {
            "ãƒªãƒ—ãƒ©ã‚¤èª˜ç™ºåŠ›": 25, "æ»åœ¨æ™‚é–“": 20, "ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ»ä¼šè©±": 15, "ãƒˆãƒ¼ãƒ³": 15,
            "ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯èª˜ç™º": 10, "ãƒ—ãƒ­ãƒ•ã‚¯ãƒªãƒƒã‚¯èª˜ç™º": 10, "æ—©æœŸåå¿œæ€§": 5,
        }
        FACTOR_ADVICE = {
            "ãƒªãƒ—ãƒ©ã‚¤èª˜ç™ºåŠ›": "ç–‘å•å½¢ãƒ»ã€Œã¿ã‚“ãªã¯ã©ã†æ€ã†ï¼Ÿã€ãªã©æ„è¦‹ã‚’æ±‚ã‚ã‚‹ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’è¿½åŠ ",
            "æ»åœ¨æ™‚é–“": "å…·ä½“çš„ãªæ•°å­—ãƒ»ç®‡æ¡æ›¸ããƒ»ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ§‹é€ ã§èª­ã¾ã›ã‚‹å·¥å¤«ã‚’",
            "ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ»ä¼šè©±": "ã‚¹ãƒ¬ãƒƒãƒ‰å½¢å¼ã‚’è©¦ã™ï¼ˆ3å€ãƒ–ãƒ¼ã‚¹ãƒˆï¼‰ã€‚ã€Œâ†“è©³ç´°ã¯ã€ãªã©ã§èª˜å°",
            "ãƒˆãƒ¼ãƒ³": "å­¦ã³ãƒ»ä½“é¨“ãƒ»ææ¡ˆã®å»ºè¨­çš„ãƒˆãƒ¼ãƒ³ã«ã€‚æ„Ÿæƒ…çš„æ‰¹åˆ¤ã¯æ§ãˆã‚‹",
            "ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯èª˜ç™º": "ã€Œâ—‹â—‹é¸ã€ã€Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã€ã€Œãƒ†ãƒ³ãƒ—ãƒ¬ã€å½¢å¼ã§ä¿å­˜ä¾¡å€¤UP",
            "å¤–éƒ¨ãƒªãƒ³ã‚¯": "å¤–éƒ¨ãƒªãƒ³ã‚¯ã¯æœ¬æ–‡ã§ã¯ãªããƒªãƒ—ãƒ©ã‚¤ã«æ›¸ãï¼ˆ50%æ¸›è¡°å›é¿ï¼‰",
            "ãƒ—ãƒ­ãƒ•ã‚¯ãƒªãƒƒã‚¯èª˜ç™º": "ã€Œå®Ÿã¯ç§â€¦ã€ã€Œã“ã“ã ã‘ã®è©±ã€ã§ã€Œèª°ï¼Ÿã€ã¨æ€ã‚ã›ã‚‹",
            "æ—©æœŸåå¿œæ€§": "å†’é ­30å­—ä»¥å†…ã«ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ»æ„Ÿæƒ…ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã‚‹",
        }

        weak = [
            (k, v) for k, v in algo_result["factors"].items()
            if FACTOR_MAX.get(k, 0) > 0 and v < FACTOR_MAX.get(k, 10) * 0.5
        ]
        if weak:
            st.subheader("æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ")
            for k, v in sorted(weak, key=lambda x: FACTOR_MAX.get(x[0], 10) - x[1], reverse=True):
                advice = FACTOR_ADVICE.get(k, "")
                st.write(f"âš ï¸ **{k}**ï¼ˆ{v}/{FACTOR_MAX.get(k, 10)}ç‚¹ï¼‰: {advice}")
        else:
            st.success("å…¨è¦ç´ ã®ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã§ã™ã€‚ã“ã®ã¾ã¾æŠ•ç¨¿ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")

        if early_result["signals"]:
            st.caption("æ—©æœŸã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚°ãƒŠãƒ«: " + " / ".join(early_result["signals"]))

    st.divider()

    # ---- 2. DBå…¨ä½“ã®Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ†æ ----
    st.subheader("2. DBå…¨ä½“ã®Xã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åˆ†æ")

    if total > 0:
        if st.button("DBå…¨ä½“ã‚’åˆ†æ", key="algo_db_btn"):
            conn = get_conn()
            df_algo_raw = pd.read_sql(
                "SELECT text, likes, retweets, replies, account FROM posts WHERE likes > 0",
                conn
            )
            conn.close()
            df_algo_jp = df_algo_raw.rename(columns={
                "text": "æœ¬æ–‡", "likes": "ã„ã„ã­æ•°",
                "retweets": "ãƒªãƒã‚¹ãƒˆæ•°", "replies": "ãƒªãƒ—ãƒ©ã‚¤æ•°", "account": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å",
            })

            with st.spinner("åˆ†æä¸­..."):
                disc = analyze_discussion_algorithm_value(df_algo_jp)
                thread = analyze_thread_potential(df_algo_jp)
                link = analyze_link_impact(df_algo_jp)
                tone_dist = analyze_tone_distribution(df_algo_jp)
                dwell = analyze_dwell_potential(df_algo_jp)
                early_all = analyze_early_engagement_potential(df_algo_jp)

            # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åŠ é‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            st.markdown("### ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åŠ é‡ã‚¹ã‚³ã‚¢ TOP10")
            st.caption("ã„ã„ã­Ã—0.5 + RTÃ—1.0 + ãƒªãƒ—ãƒ©ã‚¤Ã—13.5ï¼ˆXã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å…¬å¼é‡ã¿ï¼‰")
            if disc["top10_by_algorithm"]:
                df_disc = pd.DataFrame([
                    {
                        "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ": r["user"],
                        "ã„ã„ã­": r["likes"],
                        "RT": r["retweets"],
                        "ãƒªãƒ—ãƒ©ã‚¤": r["replies"],
                        "åŠ é‡ã‚¹ã‚³ã‚¢": round(r["weighted_score"]),
                        "è­°è«–ç‡": round(r["discussion_rate"], 3),
                        "æœ¬æ–‡": r["text"],
                    }
                    for r in disc["top10_by_algorithm"]
                ])
                st.dataframe(df_disc, use_container_width=True, hide_index=True)

            col_x1, col_x2 = st.columns(2)

            with col_x1:
                st.markdown("### ã‚¹ãƒ¬ãƒƒãƒ‰ vs å˜ç™º")
                df_th = pd.DataFrame([
                    {"ç¨®åˆ¥": "ã‚¹ãƒ¬ãƒƒãƒ‰å‹", "ä»¶æ•°": thread["thread_count"],
                     "å¹³å‡ã„ã„ã­": round(thread["thread_avg_likes"])},
                    {"ç¨®åˆ¥": "å˜ç™ºæŠ•ç¨¿", "ä»¶æ•°": thread["non_thread_count"],
                     "å¹³å‡ã„ã„ã­": round(thread["non_thread_avg_likes"])},
                ])
                st.dataframe(df_th, use_container_width=True, hide_index=True)
                if thread["non_thread_avg_likes"] > 0:
                    ratio = thread["thread_avg_likes"] / thread["non_thread_avg_likes"]
                    st.caption(f"ã‚¹ãƒ¬ãƒƒãƒ‰ã¯å˜ç™ºã® {ratio:.1f} å€")

                st.markdown("### ãƒªãƒ³ã‚¯æœ‰ç„¡ã®å½±éŸ¿")
                df_lk = pd.DataFrame([
                    {"ãƒªãƒ³ã‚¯": "å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚ã‚Š", "ä»¶æ•°": link["external_count"],
                     "å¹³å‡ã„ã„ã­": round(link["external_avg_likes"])},
                    {"ãƒªãƒ³ã‚¯": "Xå†…ãƒªãƒ³ã‚¯", "ä»¶æ•°": link["x_link_count"],
                     "å¹³å‡ã„ã„ã­": round(link["x_link_avg_likes"])},
                    {"ãƒªãƒ³ã‚¯": "ãƒªãƒ³ã‚¯ãªã—", "ä»¶æ•°": link["no_link_count"],
                     "å¹³å‡ã„ã„ã­": round(link["no_link_avg_likes"])},
                ])
                st.dataframe(df_lk, use_container_width=True, hide_index=True)
                if link["reach_penalty_confirmed"]:
                    st.caption("ãƒ‡ãƒ¼ã‚¿ã§ç¢ºèª: ãƒªãƒ³ã‚¯ãªã—æŠ•ç¨¿ã®æ–¹ãŒå¹³å‡ã„ã„ã­ãŒé«˜ã„")

            with col_x2:
                st.markdown("### Grokãƒˆãƒ¼ãƒ³åˆ†å¸ƒ")
                df_tn = pd.DataFrame([
                    {
                        "ãƒˆãƒ¼ãƒ³": k,
                        "ä»¶æ•°": v,
                        "å¹³å‡ã„ã„ã­": round(tone_dist["tone_avg_likes"].get(k, 0)),
                    }
                    for k, v in sorted(
                        tone_dist["tone_distribution"].items(),
                        key=lambda x: tone_dist["tone_avg_likes"].get(x[0], 0),
                        reverse=True,
                    )
                ])
                st.dataframe(df_tn, use_container_width=True, hide_index=True)

                st.markdown("### æ—©æœŸåå¿œé€Ÿåº¦åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
                df_ev = pd.DataFrame([
                    {
                        "é€Ÿåº¦": v,
                        "ä»¶æ•°": early_all["velocity_counts"].get(v, 0),
                        "å¹³å‡ã„ã„ã­": round(early_all["velocity_avg_likes"].get(v, 0)),
                    }
                    for v in ["é«˜é€Ÿ", "ä¸­é€Ÿ", "ä½é€Ÿ"]
                ])
                st.dataframe(df_ev, use_container_width=True, hide_index=True)

            st.markdown("### æ»åœ¨æ™‚é–“ã‚¹ã‚³ã‚¢å¸¯åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹")
            df_dw = pd.DataFrame([
                {
                    "æ»åœ¨æ™‚é–“å¸¯": k,
                    "ä»¶æ•°": dwell["bucket_counts"].get(k, 0),
                    "å¹³å‡ã„ã„ã­": round(dwell["bucket_avg_likes"].get(k, 0)),
                }
                for k in ["é«˜(15-20)", "ä¸­(10-14)", "ä½(0-9)"]
            ])
            st.dataframe(df_dw, use_container_width=True, hide_index=True)

            if disc.get("cat_algorithm_scores"):
                st.markdown("### ã‚«ãƒ†ã‚´ãƒªåˆ¥ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åŠ é‡ã‚¹ã‚³ã‚¢")
                df_cat = pd.DataFrame([
                    {"ã‚«ãƒ†ã‚´ãƒª": k, "å¹³å‡åŠ é‡ã‚¹ã‚³ã‚¢": round(v)}
                    for k, v in sorted(
                        disc["cat_algorithm_scores"].items(), key=lambda x: x[1], reverse=True
                    )
                ])
                fig_c = px.bar(df_cat, x="ã‚«ãƒ†ã‚´ãƒª", y="å¹³å‡åŠ é‡ã‚¹ã‚³ã‚¢")
                fig_c.update_xaxes(tickangle=-45)
                fig_c.update_layout(margin=dict(t=20, b=80))
                st.plotly_chart(fig_c, use_container_width=True)
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
